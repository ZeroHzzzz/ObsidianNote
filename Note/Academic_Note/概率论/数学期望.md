## 数学期望

### 离散型随机变量的数学期望

设离散型随机变量 $X$ 的分布列 $P(X=x_i)=p_i$（$i=1,2,\cdots$）。若级数 $\sum\limits_{i=1}^\infty x_ip_i$ 绝对收敛，即 $\sum\limits_{i=1}^\infty |x_i|p_i < \infty$，则称 $\sum\limits_{i=1}^\infty x_i p_i$ 为 $X$ 的**数学期望或均值**，记为 $E(X)$。即
$$
E(X) = \sum\limits_{i=1}^\infty x_i p_i
$$
 当 $\sum\limits_{i=1}^\infty |x_i| p_i$ 发散时，称 $X$ 的数学期望不存在。

### 连续型随机变量的数学期望

设 $X$ 是连续型随机变量，其密度函数为 $f(x)$，若 $\int_{-\infty}^{+\infty} xf(x)dx$ 绝对收敛，则称 $\int_{-\infty}^{+\infty} xf(x)dx$ 为 $X$ 的**数学期望或均值**，即
$$
E(X) = \int_{-\infty}^{+\infty}xf(x)dx
$$
 物理意义：以 $f(x)$ 为密度的一维连续质点系重心坐标。

### 二维随机变量函数的数学期望

设 $Z = g(X,Y)$，$g(x,y)$ 为连续函数。

1. 若 $(X,Y)$ 是二维离散型随机变量，其分布列 $P(X=x_i,Y=y_i)=p_{ij}$（$i,j=1,2,\cdots$），且
   $$
   \sum\limits_{i=1}^\infty\sum\limits_{j=1}^\infty |g(x_i,y_j)| p_{ij} < +\infty
   $$
   则
   $$
   E(Z) = E[g(X,Y)] = \sum\limits_{i=1}^\infty \sum\limits_{j=1}^\infty g(x_i,y_j) p_{ij}
   $$

2. 若 $X,Y$ 是二维连续型随机变量，其概率密度为 $f(x,y)$，且 $\int_{-infty}^{+\infty}\int_{-\infty}^{+\infty}|g(x,y)|f(x,y)dxdy < +\infty$，则
   $$
   E(Z) = E[g(X,Y)] = \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}g(x,y)f(x,y)dxdy
   $$
   特别的
   $$
   E(X) = \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}xf(x,y)dxdy \\
   E(Y) = \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}yf(x,y)dxdy
   $$

### 数学期望的性质

1. 设 $C$ 是常数，则 $E(C)=C$
2. $E(CX) = CE(X)$，$C$ 是常数
3. $E[\sum\limits_{i=1}^n X_i] = \sum\limits_{i=1}^n E(X_i)$
4. 设 $X_1,X_2,\cdots,X_n$ 相互独立，则 $E[\prod\limits_{i=1}^n X_i] = \prod\limits_{i=1}^n E(X_i)$

## 方差

设 $X$ 是一个随机变量，若 $E[X-E(X)]^2$ 存在，则称 $E[X-E(X)]^2$ 是 $X$ 的**方差**，记作 $D(X)$，即
$$
D(X) = E[X-E(X)]^2
$$
称 $\sqrt{D(X)}$ 是 $X$ 的**标准差或均方差**，记为 $\sigma_X$，即
$$
\sigma_X = \sqrt{D(X)}
$$
方差刻画了随机变量的取值对于其数学期望的离散程度。

计算方差的一个简化公式
$$
D(X) = E(X^2) - [E(X)]^2
$$

### 方差的性质

1. 设 $C$ 是常数，则 $D(C) = 0$

2. 若 $C$ 是常数，则 $D(CX) = C^2D(x)$

3. $D(X+Y) = D(X) + D(Y) + 2E\{[X-E(X)][Y-E(Y)]\}$。特别的，若 $X$ 与 $Y$ 独立，则
   $$
   D(X+Y) = D(X) + D(Y)
   $$

4. 若 $X$ 与 $Y$ 独立，则 $D(XY) = D(X)D(Y) + D(X)[E(Y)]^2 + D(Y)[E(X)]^2$

5. $D(X)=0 \Leftrightarrow P(X=C)=1$，且 $C=E(X)$

## 常用分布的期望和方差

- 若 $X\sim B(n,p)$，则 $E(X)=np$，$D(X)=np(1-p)$
- 若 $X\sim P(\lambda)$，则 $E(X)=D(X)=\lambda$（$\lambda > 0$）
- 若 $X \sim G(p)$，则 $E(X) = \frac{1}{p}$，$D(X)=\frac{1-p}{p^2}$
- 若 $X \sim U(a,b)$，则 $E(X) = \frac{a+b}{2}$，$D(X) = \frac{(b-a)^2}{12}$
- 若 $X\sim E(\lambda)$，则 $E(X)=\frac{1}{\lambda}$，$D(X) = \frac{1}{\lambda^2}$
- 若 $X\sim N(\mu,\sigma^2)$，则 $E(X)=\mu$，$D(X)=\sigma^2$（$\sigma > 0$）

## 协方差

若 $E\{[X-E(X)][Y-E(Y)]\}$ 存在，称它为随机变量 $X$ 和 $Y$ 的**协方差**，记为 $\operatorname{Cov}(X,Y)$，即
$$
\operatorname{Cov}(X,Y) = E\{[X-E(X)][Y-E(Y)] \}
$$
此时
$$
D(X \pm Y) = D(X) + D(Y) \pm \operatorname{Cov}(X,Y)
$$

- 当 $\operatorname{Cov}(X,Y) > 0$ 时，称 $X$ 与 $Y$ 正相关
- 当 $\operatorname{Cov}(X,Y) < 0$ 时，称 $X$ 与 $Y$ 负相关
- 当 $\operatorname{Cov}(X,Y) = 0$ 时，称 $X$ 与 $Y$ 不相关

**协方差**是表示两个随机变量之间**线性相关程度**的一个有量纲的数字特征。

计算协方差的一个简化公式
$$
\operatorname{Cov}(X,Y) = E(XY) - E(X)E(Y)
$$

### 协方差的性质

1. $\operatorname{Cov}(X,Y) = \operatorname{Cov}(Y,X)$，$\operatorname{Cov}(X,a)=0$
2. $D(X) = \operatorname{Cov}(X,X)$
3. $\operatorname{Cov}(aX,bY) = ab\operatorname{Cov}(X,Y)$
4. $\operatorname{Cov}(X_1+X_2,Y) = \operatorname{Cov}(X_1,Y) + \operatorname{Cov}(X_2, Y)$
5. 若 $X$ 与 $Y$ 独立，则 $\operatorname{Cov}(X,Y)=0$

## 相关系数

若 $\operatorname{Cov}(X,Y)$ 存在，且 $D(X)>0$，$D(Y)>0$，称
$$
\rho_{XY} = \frac{\operatorname{Cov}(X,Y)}{\sqrt{D(X)D(Y)}}
$$
为随机变量 $X$ 和 $Y$ 的**相关系数**。

**相关系数**是表示两个随机变量之间**线性相关程度**的一个无量纲的数字特征。

### 相关系数的性质

1. $|\rho| \le 1$
2. $|\rho| = 1 \Leftrightarrow$ 存在常数 $a,b$，使 $P(Y = a + bX) = 1$。当 $\rho = 1$ 时，$b>0$；当 $\rho = -1$ 时，$b<0$。
3. $\rho = 0 \Leftrightarrow \operatorname{Cov}(X,Y) = 0 \Leftrightarrow E(XY) = E(X)E(Y) \Leftrightarrow D(X\pm Y) = D(X) + D(Y)$

## 原点矩

若 $E(X^k)$（$k=1,2,\cdots$）存在，则称 $E(X^k)$ 为 $X$ 的 **$k$ 阶原点矩**，记为 $a_k = E(X^k)$。

## 中心距

若 $E[X-E(X)]^k$（$k=1,2,\cdots$）存在，则称 $E[X-E(X)]^k$ 为 $X$ 的 **$k$ 阶中心距**，记为 $\beta_k = E[X - E(X)]^k$。

## 混合原点矩

若 $E(X^kY^l)$（$k,l=1,2,\cdots$）存在，则称 $E(X^kY^l)$ 为 $X$ 和 $Y$ 的 **$k+l$ 阶混合原点矩**，记为 $a_{k,l} = E(X^kY^l)$。

## 混合中心距

若 $E\left\{[X-E(X)]^k[Y-E(Y)]^l \right\}$（$k,l=1,2,\cdots$）存在，则称 $E\left\{[X-E(X)]^k[Y-E(Y)]^l \right\}$ 为 $X$ 和 $Y$ 的 **$k+l$ 阶混合中心距**，记为 $\beta_{k,l} = E\left\{[X-E(X)]^k[Y-E(Y)]^l \right\}$。 

## 大数定律

### 依概率收敛

设 $Z_1,Z_2,\cdots,Z_n,\cdots$ 是一个随机变量序列，$a$ 是一个常数，若对任意 $\varepsilon > 0$ 有
$$
\lim\limits_{n\to\infty} P(|Z_n - a| < \varepsilon) = 1
$$
或
$$
\lim\limits_{n\to\infty} P(|Z_n - a|\ge \varepsilon) = 0
$$
则称序列 $Z_1,Z_2,\cdots,Z_n,\cdots$ **依概率收敛**于 $a$，记为
$$
\lim\limits_{n\to\infty}Z_n = a \quad 或 \quad Z_n \to a(n\to\infty)
$$

### 切比雪夫不等式

对任意随机变量 $X$，若 $D(X)$ 存在，则对任意 $\varepsilon > 0$ 有
$$
P[|X-E(X)|\ge \varepsilon] \le \frac{D(X)}{\varepsilon^2}
$$
或
$$
P[|X-E(X)|<\varepsilon] \ge 1 - \frac{D(X)}{\varepsilon^2}
$$

### 伯努利大数定律

设 $Y_n$ 是 $n$ 重伯努利试验中事件 $A$ 发生的次数，$p$（$0<p<1$）是事件 $A$ 发生的概率，则对任给的 $\varepsilon > 0$，有
$$
\lim\limits_{n\to\infty}P\left\{\left|\frac{Y_n}{n} - p\right|\ge \varepsilon\right\} = 0
$$
或
$$
\lim\limits_{n\to\infty}P\left\{\left|\frac{Y_n}{n} - p\right|< \varepsilon\right\} = 1
$$
伯努利大数定律提供了用频率来确定概率的理论依据。

### 独立同分布随机变量序列

若随机变量序列 $X_1,X_2,\cdots,X_n,\cdots$ 相互独立，对 $n\ge 2$，$X_1,X_2,\cdots,X_n$ 独立，且有相同的分布函数，则称 $X_1,X_2,\cdots,X_n,\cdots$ 是独立同分布的随机变量序列。

### 切比雪夫大数定律

设 $X_1,X_2,\cdots,X_n,\cdots$ 是相互独立的随机变量序列。它们都有有限的方差，并且方差有共同的上界，即 $D(X_i) \le C$（$i=1,2,\cdots$），则对任意 $\varepsilon > 0$，有
$$
\lim\limits_{n\to\infty}P \left\{\left|\frac{1}{n}\sum\limits_{i=1}^n X_i - \frac{1}{n}\sum\limits_{i=1}^n E(X_i)\right| \ge \varepsilon \right\} = 0
$$

### 辛钦大数定律

设 $X_1,X_2,\cdots$ 是独立同分布的随机变量序列，且 $E(X_i) = \mu$，（$i=1,2,\cdots$），则对任给 $\varepsilon > 0$，有
$$
\lim\limits_{n\to\infty} P\{|\frac{1}{n}X_i-\mu|\ge \varepsilon \} = 0
$$
这是随机变量序列的算术平均值稳定性的较确切的解释。

## 中心极限定理

设 $X_1,X_2,\cdots$ 是独立同分布的随机变量序列，且 $E(X_i) = \mu$，$D(X_i) = \sigma^2 > 0$（$i=1,2,\cdots$）存在，则对充分大的 $n$，有
$$
\sum\limits_{i=1}^n X_i \overset{近似}{\sim} N(n\mu,n\sigma^2) \\
P(a<\sum\limits_{i=1}^n X_i \le b) \approx \Phi(\frac{b-n\mu}{\sqrt{n}\sigma}) - \Phi(\frac{a-n\mu}{\sqrt{n}\sigma}
$$
此定理也称为**中心极限定理**。

### 棣莫佛——拉普拉斯定理

设随机变量 $Y_n$ 服从参数 $n,p$（$0<p<1$）的二项分布，则对充分大的 $n$，有
$$
Y_n \overset{近似}{\sim} N(np,npq)
$$
其中 $q = 1-p$，即
$$
P(a<Y_n \le b) \approx \Phi(\frac{b-np}{\sqrt{npq}}) - \Phi(\frac{a-np}{\sqrt{npq}})
$$
在实际中，当 $0.1<p < 0.9$ 且 $npq > 9$ 时，用正态分布近似；

当 $p\le 0.1$ 且 $n\ge 10$ 时，用泊松分布近似。

不难发现，棣莫佛——拉普拉斯定理是中心极限定理的一个特例。